---
- name: Install and Configure Hadoop on Ubuntu
  hosts: all
  become: yes
  vars:
    hadoop_user: "hadoop"
    hadoop_home: "/usr/local/hadoop"
    java_home: "/usr/lib/jvm/java-11-openjdk-amd64"

  tasks:
    ## ðŸŸ¢ Ã‰tape 1 : Mise Ã  jour du systÃ¨me et installation de Java
    - name: Update package lists
      apt:
        update_cache: yes

    - name: Install Java
      apt:
        name:
          - default-jdk
          - default-jre
        state: present

    - name: Verify Java installation
      command: java -version
      register: java_version
      changed_when: false

    - name: Display Java version
      debug:
        msg: "{{ java_version.stdout_lines }}"

    ## ðŸŸ¢ Ã‰tape 2 : CrÃ©ation de l'utilisateur Hadoop et configuration SSH
    - name: Create Hadoop user
      user:
        name: "{{ hadoop_user }}"
        groups: sudo
        append: yes
        shell: /bin/bash
        createhome: yes

    - name: Install OpenSSH server and client
      apt:
        name:
          - openssh-server
          - openssh-client
        state: present

    - name: Generate SSH key for Hadoop user
      command: ssh-keygen -t rsa -N '' -f /home/{{ hadoop_user }}/.ssh/id_rsa
      args:
        creates: /home/{{ hadoop_user }}/.ssh/id_rsa
      become_user: "{{ hadoop_user }}"

    - name: Add SSH key to authorized_keys
      shell: cat /home/{{ hadoop_user }}/.ssh/id_rsa.pub >> /home/{{ hadoop_user }}/.ssh/authorized_keys
      become_user: "{{ hadoop_user }}"

    - name: Set correct permissions for authorized_keys
      file:
        path: /home/{{ hadoop_user }}/.ssh/authorized_keys
        mode: '0640'
        owner: "{{ hadoop_user }}"
        group: "{{ hadoop_user }}"

    ## ðŸŸ¢ Ã‰tape 3 : TÃ©lÃ©chargement et Installation de Hadoop
    - name: Download Hadoop
      get_url:
        url: "https://downloads.apache.org/hadoop/common/stable/hadoop-3.3.4.tar.gz"
        dest: "/tmp/hadoop.tar.gz"

    - name: Extract Hadoop
      unarchive:
        src: "/tmp/hadoop.tar.gz"
        dest: "/usr/local/"
        remote_src: yes

    - name: Rename Hadoop directory
      command: mv /usr/local/hadoop-3.3.4 /usr/local/hadoop
      args:
        removes: /usr/local/hadoop-3.3.4
        creates: "{{ hadoop_home }}"

    - name: Create logs directory
      file:
        path: "{{ hadoop_home }}/logs"
        state: directory
        owner: "{{ hadoop_user }}"
        group: "{{ hadoop_user }}"
        mode: '0755'

    - name: Change ownership of Hadoop directory
      file:
        path: "{{ hadoop_home }}"
        state: directory
        owner: "{{ hadoop_user }}"
        group: "{{ hadoop_user }}"
        recurse: yes

    ## ðŸŸ¢ Ã‰tape 4 : Configuration des variables d'environnement Hadoop
    - name: Set Hadoop environment variables in .bashrc
      blockinfile:
        path: "/home/{{ hadoop_user }}/.bashrc"
        block: |
          export HADOOP_HOME={{ hadoop_home }}
          export HADOOP_INSTALL=$HADOOP_HOME
          export HADOOP_MAPRED_HOME=$HADOOP_HOME
          export HADOOP_COMMON_HOME=$HADOOP_HOME
          export HADOOP_HDFS_HOME=$HADOOP_HOME
          export YARN_HOME=$HADOOP_HOME
          export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
          export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin
          export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native"

    - name: Apply environment changes
      shell: source /home/{{ hadoop_user }}/.bashrc
      become_user: "{{ hadoop_user }}"

    ## ðŸŸ¢ Ã‰tape 5 : Configuration de Java dans Hadoop
    - name: Set JAVA_HOME in Hadoop environment
      lineinfile:
        path: "{{ hadoop_home }}/etc/hadoop/hadoop-env.sh"
        regexp: '^export JAVA_HOME='
        line: 'export JAVA_HOME={{ java_home }}'
        state: present

    - name: Download javax activation jar
      get_url:
        url: "https://jcenter.bintray.com/javax/activation/javax.activation-api/1.2.0/javax.activation-api-1.2.0.jar"
        dest: "{{ hadoop_home }}/lib/javax.activation-api-1.2.0.jar"

    ## ðŸŸ¢ Ã‰tape 6 : Configuration des fichiers XML de Hadoop
    - name: Configure core-site.xml
      copy:
        dest: "{{ hadoop_home }}/etc/hadoop/core-site.xml"
        content: |
          <configuration>
            <property>
              <name>fs.default.name</name>
              <value>hdfs://0.0.0.0:9000</value>
              <description>The default file system URI</description>
            </property>
          </configuration>

    - name: Create HDFS directories
      file:
        path: "/home/{{ hadoop_user }}/hdfs/{{ item }}"
        state: directory
        owner: "{{ hadoop_user }}"
        group: "{{ hadoop_user }}"
        mode: '0755'
      loop:
        - namenode
        - datanode

    - name: Configure hdfs-site.xml
      copy:
        dest: "{{ hadoop_home }}/etc/hadoop/hdfs-site.xml"
        content: |
          <configuration>
            <property>
              <name>dfs.replication</name>
              <value>1</value>
            </property>
            <property>
              <name>dfs.name.dir</name>
              <value>file:///home/hadoop/hdfs/namenode</value>
            </property>
            <property>
              <name>dfs.data.dir</name>
              <value>file:///home/hadoop/hdfs/datanode</value>
            </property>
          </configuration>

    - name: Configure mapred-site.xml
      copy:
        dest: "{{ hadoop_home }}/etc/hadoop/mapred-site.xml"
        content: |
          <configuration>
            <property>
              <name>mapreduce.framework.name</name>
              <value>yarn</value>
            </property>
          </configuration>

    - name: Configure yarn-site.xml
      copy:
        dest: "{{ hadoop_home }}/etc/hadoop/yarn-site.xml"
        content: |
          <configuration>
            <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
            </property>
          </configuration>

    ## ðŸŸ¢ Ã‰tape 7 : VÃ©rification de l'installation de Hadoop
    - name: Check Hadoop version
      command: "{{ hadoop_home }}/bin/hadoop version"
      register: hadoop_version
      changed_when: false

    - name: Display Hadoop version
      debug:
        msg: "{{ hadoop_version.stdout_lines }}"
