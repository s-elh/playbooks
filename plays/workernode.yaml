---
- name: Setup Hadoop Cluster Nodes
  hosts: all
  become: yes
  become_user: hdoop
  vars:
    hadoop_version: "3.4.0"
    hadoop_home: "/home/hdoop/hadoop-{{ hadoop_version }}"
    hadoop_download_url: "https://dlcdn.apache.org/hadoop/common/hadoop-{{ hadoop_version }}/hadoop-{{ hadoop_version }}.tar.gz"
    hadoop_download_path: "/home/hdoop/hadoop-{{ hadoop_version }}.tar.gz"

  tasks:
    ## 游릭 Step 1: Cleanup old Hadoop installation
    - name: Remove old Hadoop installation
      file:
        path: "{{ item }}"
        state: absent
      with_items:
        - "/home/hdoop/hadoop-*"
        - "/home/hdoop/tmpdata"
        - "/home/hdoop/namenode"
        - "/home/hdoop/datanode"

    ## 游릭 Step 2: Download new Hadoop
    - name: Download Hadoop {{ hadoop_version }}
      get_url:
        url: "{{ hadoop_download_url }}"
        dest: "{{ hadoop_download_path }}"
        mode: '0644'

    ## 游릭 Step 3: Extract Hadoop
    - name: Extract Hadoop tarball
      unarchive:
        src: "{{ hadoop_download_path }}"
        dest: "/home/hdoop"
        remote_src: yes
        creates: "{{ hadoop_home }}"

    ## 游릭 Step 4: Stop firewalld service
    - name: Stop firewalld service
      become: yes
      become_user: root
      service:
        name: firewalld
        state: stopped
        enabled: no
      ignore_errors: yes

- name: Configure NameNode
  hosts: namenode
  become: yes
  become_user: hdoop
  vars_prompt:
    - name: namenode_dir
      private: no
      prompt: "Enter location directory path for Name Node"
  tasks:
    - name: Create NameNode Directory
      file:
        path: "{{ namenode_dir }}"
        state: directory
        owner: hdoop
        group: hdoop
        mode: '0750'

    - name: Configure hdfs-site.xml for NameNode
      blockinfile:
        path: "{{ hadoop_home }}/etc/hadoop/hdfs-site.xml"
        insertafter: "<configuration>"
        block: |
          <property>
              <name>dfs.namenode.name.dir</name>
              <value>{{ namenode_dir }}</value>
          </property>
          <property>
              <name>dfs.replication</name>
              <value>3</value>
          </property>

    - name: Configure core-site.xml for NameNode
      blockinfile:
        path: "{{ hadoop_home }}/etc/hadoop/core-site.xml"
        insertafter: "<configuration>"
        block: |
          <property>
              <name>fs.defaultFS</name>
              <value>hdfs://{{ groups['namenode'][0] }}:9000</value>
          </property>

    - name: Format NameNode
      command: "{{ hadoop_home }}/bin/hdfs namenode -format -force"
      ignore_errors: yes

    - name: Start NameNode daemon
      command: "{{ hadoop_home }}/bin/hdfs --daemon start namenode"
      ignore_errors: yes

- name: Configure DataNode
  hosts: datanode
  become: yes
  become_user: hdoop
  vars_prompt:
    - name: datanode_dir
      private: no
      prompt: "Enter location directory path for Data Node"
  tasks:
    - name: Create DataNode Directory
      file:
        path: "{{ datanode_dir }}"
        state: directory
        owner: hdoop
        group: hdoop
        mode: '0750'

    - name: Configure hdfs-site.xml for DataNode
      blockinfile:
        path: "{{ hadoop_home }}/etc/hadoop/hdfs-site.xml"
        insertafter: "<configuration>"
        block: |
          <property>
              <name>dfs.datanode.data.dir</name>
              <value>{{ datanode_dir }}</value>
          </property>

    - name: Configure core-site.xml for DataNode
      blockinfile:
        path: "{{ hadoop_home }}/etc/hadoop/core-site.xml"
        insertafter: "<configuration>"
        block: |
          <property>
              <name>fs.defaultFS</name>
              <value>hdfs://{{ groups['namenode'][0] }}:9000</value>
          </property>

    - name: Start DataNode daemon
      command: "{{ hadoop_home }}/bin/hdfs --daemon start datanode"
      ignore_errors: yes
