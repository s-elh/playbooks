---
- name: Install Hadoop on Ubuntu
  hosts: all
  become: yes
  vars:
    hadoop_version: "3.3.6"
    hadoop_user: "hadoop"
    hadoop_group: "hadoop"
    hadoop_home: "/usr/local/hadoop"
    java_home: "/usr/lib/jvm/java-11-openjdk-amd64"
    hadoop_url: "https://downloads.apache.org/hadoop/common/hadoop-{{ hadoop_version }}/hadoop-{{ hadoop_version }}.tar.gz"

  tasks:
    - name: Update and install dependencies
      apt:
        update_cache: yes
        name:
          - default-jdk
          - ssh
          - rsync
        state: present

    - name: Verify Java installation
      command: java -version
      register: java_version
      changed_when: false

    - name: Display Java version
      debug:
        msg: "{{ java_version.stderr_lines }}"

    - name: Ensure hadoop group exists
      group:
        name: "{{ hadoop_group }}"
        state: present

    - name: Ensure hadoop user exists
      user:
        name: "{{ hadoop_user }}"
        group: "{{ hadoop_group }}"
        shell: /bin/bash
        createhome: yes
        home: "/home/{{ hadoop_user }}"

    - name: Download Hadoop
      get_url:
        url: "{{ hadoop_url }}"
        dest: "/tmp/hadoop.tar.gz"

    - name: Extract Hadoop archive
      unarchive:
        src: "/tmp/hadoop.tar.gz"
        dest: "/usr/local/"
        remote_src: yes

    - name: Rename Hadoop directory
      command: mv /usr/local/hadoop-{{ hadoop_version }} /usr/local/hadoop
      args:
        creates: "{{ hadoop_home }}"

    - name: Change ownership of Hadoop directory
      file:
        path: "{{ hadoop_home }}"
        owner: "{{ hadoop_user }}"
        group: "{{ hadoop_group }}"
        recurse: yes

    - name: Set Hadoop environment variables in .bashrc
      blockinfile:
        path: "/home/{{ hadoop_user }}/.bashrc"
        block: |
          export JAVA_HOME={{ java_home }}
          export HADOOP_HOME={{ hadoop_home }}
          export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
        create: yes

    - name: Apply environment changes
      shell: "source /home/{{ hadoop_user }}/.bashrc"
      args:
        executable: /bin/bash

    - name: Check Hadoop version
      command: "{{ hadoop_home }}/bin/hadoop version"
      register: hadoop_version
      changed_when: false

    - name: Display Hadoop version
      debug:
        msg: "{{ hadoop_version.stdout_lines }}"

    - name: Generate SSH key for Hadoop user
      become: yes
      become_user: "{{ hadoop_user }}"
      command: ssh-keygen -t rsa -N "" -f /home/{{ hadoop_user }}/.ssh/id_rsa
      args:
        creates: "/home/{{ hadoop_user }}/.ssh/id_rsa"

    - name: Copy public key to authorized_keys
      become: yes
      become_user: "{{ hadoop_user }}"
      shell: "cat /home/{{ hadoop_user }}/.ssh/id_rsa.pub >> /home/{{ hadoop_user }}/.ssh/authorized_keys"

    - name: Set permissions for SSH keys
      file:
        path: "/home/{{ hadoop_user }}/.ssh/authorized_keys"
        mode: '0600'
        owner: "{{ hadoop_user }}"
        group: "{{ hadoop_group }}"

    - name: Start Hadoop NameNode
      shell: "{{ hadoop_home }}/bin/hdfs namenode -format"
      become: yes
      become_user: "{{ hadoop_user }}"
      args:
        executable: /bin/bash

    - name: Start Hadoop services
      shell: "{{ hadoop_home }}/sbin/start-dfs.sh"
      become: yes
      become_user: "{{ hadoop_user }}"
      args:
        executable: /bin/bash

    - name: Verify Hadoop services
      shell: "jps"
      become: yes
      become_user: "{{ hadoop_user }}"
      register: jps_output
      args:
        executable: /bin/bash

    - name: Display running Hadoop services
      debug:
        msg: "{{ jps_output.stdout_lines }}"
